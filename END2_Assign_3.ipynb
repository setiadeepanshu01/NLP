{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "END2 - Assign 3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wb5cCNGSucOV"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Bq9xYnuubGi"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ssymKcCujFZ"
      },
      "source": [
        "## Loading the MNIST Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tryfs0quulRt"
      },
      "source": [
        "train_dataset = torchvision.datasets.MNIST(\n",
        "                    root='.',\n",
        "                    train=True,\n",
        "                    transform=transforms.ToTensor(), \n",
        "                    download=True)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(\n",
        "                    root='.',\n",
        "                    train=False,\n",
        "                    transform=transforms.ToTensor(),\n",
        "                    download=True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyFEJpkduuGS"
      },
      "source": [
        " ## Generate random numbers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i213RXOSupry"
      },
      "source": [
        "# Train Set, 60000 Samples\n",
        "number_train = torch.randint(0, 9, (60000,)) # Random Digit i.e. Second Input\n",
        "sum_train = number_train + train_dataset.targets # Sum of Random Digit and MNIST i.e. Second Output\n",
        "number_train = torch.nn.functional.one_hot(number_train, num_classes=10)\n",
        "\n",
        "# Test Set, 10000 Samples\n",
        "number_test = torch.randint(0, 9, (10000,)) # Random Digit i.e. Second Input\n",
        "sum_test = number_test + test_dataset.targets # Sum of Random Digit and MNIST i.e. Second Output\n",
        "number_test = torch.nn.functional.one_hot(number_test, num_classes=10)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C_69MdhcvFOS"
      },
      "source": [
        "## Re-creating Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F6Ui8J4MvG39"
      },
      "source": [
        "# Flattens the MNIST images\n",
        "train_x = train_dataset.data.reshape(60000, 784).float()\n",
        "test_x = test_dataset.data.reshape(10000, 784).float()\n",
        "\n",
        "# Creats the Dataset with two inputs and two outputs\n",
        "train_ds = torch.utils.data.TensorDataset(train_x, number_train, train_dataset.targets, sum_train)\n",
        "test_ds = torch.utils.data.TensorDataset(test_x, number_test, test_dataset.targets, sum_test)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G-F0OAlBvIfb"
      },
      "source": [
        "## DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpqFLHofvL-A"
      },
      "source": [
        "batch_size = 32\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "                        dataset=train_ds,\n",
        "                        batch_size=batch_size,\n",
        "                        shuffle=True\n",
        "                        )\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "                        dataset=test_ds,\n",
        "                        batch_size=batch_size,\n",
        "                        shuffle=False # Not necessary!\n",
        "                        )"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBBXOpDsvOVm"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgOtM7hEvPhu"
      },
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.lineara1 = nn.Linear(784, 30) # Flattened MNIST as Input: 28 * 28\n",
        "        self.relu = nn.ReLU()\n",
        "        self.selu = nn.SELU()\n",
        "        self.lineara2 = nn.Linear(30, 30)\n",
        "        self.lineara3 = nn.Linear(30,10) # 10 Classes for First Output: 0-9\n",
        "\n",
        "        self.linearb1 = nn.Linear(40, 60) # 10 for random digit, 30 from output of lineara1 layer\n",
        "        self.linearb2 = nn.Linear(60, 30)\n",
        "        self.linearb3 = nn.Linear(30,18) # 18 Classes for Second Output: 0-18\n",
        "            \n",
        "    def forward(self, Xa, Xb):\n",
        "\n",
        "        out = self.lineara1(Xa)\n",
        "        out1 = self.selu(out)\n",
        "        out = self.lineara2(out1)\n",
        "        out = self.selu(out)\n",
        "        out = self.lineara3(out)\n",
        "        outa = self.selu(out)\n",
        "\n",
        "\n",
        "        inb = torch.cat((out1,Xb), dim=-1) # Gets input from the first layer after the input layer\n",
        "        outb = self.linearb1(inb)\n",
        "        outb = self.relu(outb)\n",
        "        outb = self.linearb2(outb)\n",
        "        outb = self.relu(outb)\n",
        "\n",
        "        outb = self.linearb3(outb)\n",
        "        outb = self.relu(outb)\n",
        "        return outa, outb\n",
        "\n",
        "# Instantiate the Model\n",
        "model = Model()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXu7e9qSvUQx"
      },
      "source": [
        "## Move Model to GPU (Required Condition by Assignment!)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fYPA-pEIvaUS",
        "outputId": "3c5e8090-6b22-477f-9c55-ac438cb60a22"
      },
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "model.to(device)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (lineara1): Linear(in_features=784, out_features=30, bias=True)\n",
              "  (relu): ReLU()\n",
              "  (selu): SELU()\n",
              "  (lineara2): Linear(in_features=30, out_features=30, bias=True)\n",
              "  (lineara3): Linear(in_features=30, out_features=10, bias=True)\n",
              "  (linearb1): Linear(in_features=40, out_features=60, bias=True)\n",
              "  (linearb2): Linear(in_features=60, out_features=30, bias=True)\n",
              "  (linearb3): Linear(in_features=30, out_features=18, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRI8imRdvcHv"
      },
      "source": [
        "## Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qa4iXVqLvdpW",
        "outputId": "2847d41a-529d-418c-832c-d61b50818ac9"
      },
      "source": [
        "summary(model, [(1,784), (1,10)])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                [-1, 1, 30]          23,550\n",
            "              SELU-2                [-1, 1, 30]               0\n",
            "            Linear-3                [-1, 1, 30]             930\n",
            "              SELU-4                [-1, 1, 30]               0\n",
            "            Linear-5                [-1, 1, 10]             310\n",
            "              SELU-6                [-1, 1, 10]               0\n",
            "            Linear-7                [-1, 1, 60]           2,460\n",
            "              ReLU-8                [-1, 1, 60]               0\n",
            "            Linear-9                [-1, 1, 30]           1,830\n",
            "             ReLU-10                [-1, 1, 30]               0\n",
            "           Linear-11                [-1, 1, 18]             558\n",
            "             ReLU-12                [-1, 1, 18]               0\n",
            "================================================================\n",
            "Total params: 29,638\n",
            "Trainable params: 29,638\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.03\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.11\n",
            "Estimated Total Size (MB): 0.15\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kO9dQJJfvfPc"
      },
      "source": [
        "## Loss and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o79IzzV7vhae"
      },
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters())"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B6ClCvKqwO4X"
      },
      "source": [
        "## Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpql5R5EwQEd",
        "outputId": "dc749db5-e7e8-4f02-960a-2f538677a744"
      },
      "source": [
        "\n",
        "n_epochs = 20\n",
        "\n",
        "\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    train_loss = []\n",
        "    n_correcta = 0.\n",
        "    n_correctb = 0.  \n",
        "    n_total = 0.\n",
        "\n",
        "    for inputs, numbers, targets, result in train_loader:\n",
        "\n",
        "        # Move data to GPU\n",
        "        inputs, numbers, targets, result = inputs.to(device), numbers.to(device), targets.to(device), result.to(device)\n",
        "        \n",
        "        # zero the gradient\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        # forward pass\n",
        "        outputa, outputb = model(inputs, numbers)\n",
        "        lossa = loss_fn(outputa, targets)\n",
        "        lossb = loss_fn(outputb, result)\n",
        "\n",
        "        loss = lossa + lossb # Adds loss values from both outputs\n",
        "\n",
        "        # get predictiona\n",
        "        _, predictiona = torch.max(outputa, 1)\n",
        "        _, predictionb = torch.max(outputb, 1)\n",
        "\n",
        "        # update counts\n",
        "        n_correcta += (predictiona == targets).sum().item()\n",
        "        n_correctb += (predictionb == result).sum().item()\n",
        "        n_total += targets.shape[0]\n",
        " \n",
        "        # backward pass and optimize\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        train_loss.append(loss.item())\n",
        "        \n",
        "    train_loss = np.mean(train_loss)\n",
        "    train_acc_a = n_correcta / n_total * 100\n",
        "    train_acc_b = n_correctb / n_total * 100\n",
        "\n",
        "    \n",
        "    test_loss = []\n",
        "    n_correcta = 0.\n",
        "    n_correctb = 0. \n",
        "    n_total = 0.\n",
        "    \n",
        "    for inputs, numbers, targets, result in test_loader:\n",
        "\n",
        "        # Move data to GPU\n",
        "        inputs, numbers, targets, result = inputs.to(device), numbers.to(device), targets.to(device), result.to(device)\n",
        "        \n",
        "        # forward pass\n",
        "        outputa, outputb = model(inputs, numbers)\n",
        "        lossa = loss_fn(outputa, targets)\n",
        "        lossb = loss_fn(outputb, result)\n",
        "\n",
        "        loss = lossa + lossb # Adds loss values from both outputs\n",
        "                \n",
        "         # get predictions\n",
        "        _, predictiona = torch.max(outputa, 1) \n",
        "        _, predictionb = torch.max(outputb, 1)\n",
        "        \n",
        "        \n",
        "        # update counts\n",
        "        n_correcta += (predictiona == targets).sum().item()\n",
        "        n_correctb += (predictionb == result).sum().item()\n",
        "\n",
        "        n_total += targets.shape[0]\n",
        "\n",
        "        test_loss.append(loss.item())\n",
        "        \n",
        "    test_loss = np.mean(test_loss)\n",
        "    test_acc_a = n_correcta / n_total * 100\n",
        "    test_acc_b = n_correctb / n_total * 100\n",
        "    \n",
        "\n",
        "    print(f'Epoch: {epoch+1}/{n_epochs}, Train Accuracy [MNIST]: {train_acc_a:.2f}%,  Train Accuracy [Sum]: {train_acc_b:.2f}%, Train Loss: {train_loss:.4f}, Test Accuracy [MNIST]: {test_acc_a:.2f}%,  Test Accuracy [Sum]: {test_acc_b:.2f}%, Train Loss: {test_loss:.4f}')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/20, Train Accuracy [MNIST]: 78.76%,  Train Accuracy [Sum]: 11.64%, Train Loss: 3.3668, Test Accuracy [MNIST]: 83.33%,  Test Accuracy [Sum]: 12.98%, Train Loss: 3.0302\n",
            "Epoch: 2/20, Train Accuracy [MNIST]: 83.33%,  Train Accuracy [Sum]: 19.43%, Train Loss: 2.8587, Test Accuracy [MNIST]: 83.94%,  Test Accuracy [Sum]: 31.13%, Train Loss: 2.4583\n",
            "Epoch: 3/20, Train Accuracy [MNIST]: 88.69%,  Train Accuracy [Sum]: 49.07%, Train Loss: 1.8991, Test Accuracy [MNIST]: 92.82%,  Test Accuracy [Sum]: 64.43%, Train Loss: 1.4057\n",
            "Epoch: 4/20, Train Accuracy [MNIST]: 92.84%,  Train Accuracy [Sum]: 70.71%, Train Loss: 1.2434, Test Accuracy [MNIST]: 92.35%,  Test Accuracy [Sum]: 73.82%, Train Loss: 1.1752\n",
            "Epoch: 5/20, Train Accuracy [MNIST]: 93.09%,  Train Accuracy [Sum]: 78.45%, Train Loss: 1.0277, Test Accuracy [MNIST]: 93.12%,  Test Accuracy [Sum]: 78.36%, Train Loss: 1.0014\n",
            "Epoch: 6/20, Train Accuracy [MNIST]: 93.33%,  Train Accuracy [Sum]: 82.47%, Train Loss: 0.9114, Test Accuracy [MNIST]: 93.06%,  Test Accuracy [Sum]: 82.27%, Train Loss: 0.9688\n",
            "Epoch: 7/20, Train Accuracy [MNIST]: 93.49%,  Train Accuracy [Sum]: 85.27%, Train Loss: 0.8322, Test Accuracy [MNIST]: 93.66%,  Test Accuracy [Sum]: 86.36%, Train Loss: 0.8283\n",
            "Epoch: 8/20, Train Accuracy [MNIST]: 93.44%,  Train Accuracy [Sum]: 86.88%, Train Loss: 0.7805, Test Accuracy [MNIST]: 93.35%,  Test Accuracy [Sum]: 87.17%, Train Loss: 0.8106\n",
            "Epoch: 9/20, Train Accuracy [MNIST]: 93.60%,  Train Accuracy [Sum]: 87.97%, Train Loss: 0.7471, Test Accuracy [MNIST]: 93.62%,  Test Accuracy [Sum]: 89.77%, Train Loss: 0.7276\n",
            "Epoch: 10/20, Train Accuracy [MNIST]: 93.68%,  Train Accuracy [Sum]: 88.43%, Train Loss: 0.7236, Test Accuracy [MNIST]: 93.14%,  Test Accuracy [Sum]: 88.64%, Train Loss: 0.7698\n",
            "Epoch: 11/20, Train Accuracy [MNIST]: 93.73%,  Train Accuracy [Sum]: 88.71%, Train Loss: 0.7112, Test Accuracy [MNIST]: 93.62%,  Test Accuracy [Sum]: 89.49%, Train Loss: 0.7162\n",
            "Epoch: 12/20, Train Accuracy [MNIST]: 93.75%,  Train Accuracy [Sum]: 89.38%, Train Loss: 0.6793, Test Accuracy [MNIST]: 92.56%,  Test Accuracy [Sum]: 86.64%, Train Loss: 0.8836\n",
            "Epoch: 13/20, Train Accuracy [MNIST]: 94.02%,  Train Accuracy [Sum]: 89.67%, Train Loss: 0.6642, Test Accuracy [MNIST]: 93.61%,  Test Accuracy [Sum]: 89.44%, Train Loss: 0.7270\n",
            "Epoch: 14/20, Train Accuracy [MNIST]: 94.06%,  Train Accuracy [Sum]: 90.22%, Train Loss: 0.6472, Test Accuracy [MNIST]: 93.54%,  Test Accuracy [Sum]: 88.64%, Train Loss: 0.7402\n",
            "Epoch: 15/20, Train Accuracy [MNIST]: 94.01%,  Train Accuracy [Sum]: 90.02%, Train Loss: 0.6423, Test Accuracy [MNIST]: 93.64%,  Test Accuracy [Sum]: 89.91%, Train Loss: 0.6890\n",
            "Epoch: 16/20, Train Accuracy [MNIST]: 94.24%,  Train Accuracy [Sum]: 90.53%, Train Loss: 0.6199, Test Accuracy [MNIST]: 92.73%,  Test Accuracy [Sum]: 89.53%, Train Loss: 0.7497\n",
            "Epoch: 17/20, Train Accuracy [MNIST]: 94.11%,  Train Accuracy [Sum]: 90.53%, Train Loss: 0.6222, Test Accuracy [MNIST]: 93.19%,  Test Accuracy [Sum]: 89.38%, Train Loss: 0.7241\n",
            "Epoch: 18/20, Train Accuracy [MNIST]: 94.27%,  Train Accuracy [Sum]: 90.92%, Train Loss: 0.6007, Test Accuracy [MNIST]: 93.67%,  Test Accuracy [Sum]: 90.65%, Train Loss: 0.6594\n",
            "Epoch: 19/20, Train Accuracy [MNIST]: 94.34%,  Train Accuracy [Sum]: 91.02%, Train Loss: 0.5953, Test Accuracy [MNIST]: 93.83%,  Test Accuracy [Sum]: 91.01%, Train Loss: 0.6534\n",
            "Epoch: 20/20, Train Accuracy [MNIST]: 94.36%,  Train Accuracy [Sum]: 91.19%, Train Loss: 0.5857, Test Accuracy [MNIST]: 93.57%,  Test Accuracy [Sum]: 90.61%, Train Loss: 0.6606\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}